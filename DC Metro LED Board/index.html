---
layout: default
title: Kevin Craig
---

<div class="blurb">
    <h1> Live DC Metro Prediction Board with Python </h1>
    <center>
        <img src="Metro-Sign-Image-1.jpg" alt="LED Board Image">
    </center>
    <h2> <u> Overview </u></h2>
    <p>
    In April, I wrote <a> <href = https://kevcraig.github.io/DC%20Metro%20Network%20Analysis/> an analysis </a> of the DC metro system. In the process, gained access to the WMATA metro API. One endpoint of the API was current predictions for each train and station within the DC metro network, this sparked an idea for a DIY metro board for my U-Street apartment. The goal was to build something that resembles the actual train prediction screens found in DC metro stations but have it in my own living room, all made possible by the WMATA API and some hardware found on the internet. 
    </p>
    
    <h2> <u> Process </u></h2>
    <p>
    Now that the project is complete, I wanted to share my process and what I learned in my first project dealing with both hardware & software. All the code is on my <a> <href =https://github.com/kevcraig/LED-Metro-Sign>  Github</a> and can be cloned if you want to build a board for your own WMATA station. 
    </p>
    <ol>
        <li><b> Hardware: </b></li>
        <p>
            To build a real time metro prediction board, you need a screen, a computer to connect to the screen and API, and a power connection. Hardware costs $118 if you buy everything new from Adafruit.
            - Raspberry Pi ZeroWH
        </p>
        <ul>
            <li> Raspberry Pi with WIFI access and GPIO headers to connect to the AdaFruit Bonnet. Any Raspberry Pi / Adruino with these specs would work, but this was the cheapest option I could find </li>
        </ul>
        - 16GB Micro SD Card
        <ul>
            <li> SD card used for the Raspberry Pi OS and storage </li>
        </ul>
        - 64 x 32 RGB LED Matrix - 6mm pitch
            <ul>
                <li>LED Board that displays metro predictions. The pitch is the space between pixels, I choose 6mm</li>
            </ul> 
        - Adafruit RGB Matrix Bonnet for Raspberry Pi
            <ul>
                <li> Bonnet hardware between Raspberry Pi and LED board </li> 
            </ul> 
        <p>
            Basic architecture for the system is displayed below
        </p>

    <p>
    <center>
        <img src="Basic_Arch.png" alt="architecture diagram" width="400" height="300">
    </center>
    </p>
    <li> <b>Software:</b> </li>
        <p>
            I thought about software in two groups: code to pull and store train predictions from the WMATA API, and code to display train predictions on the LED board. 
        </p>
        <ol type = 'A'>
            <li> <em> Requirements </em>: Pull and store train predictions from WMATA API </li>
            <ol type = 'i'>
                <li>Connect to the WMATA API through WIFI</li>
                <li>Update every 10 seconds</li>
                <li>Donâ€™t get rate limited</li>
                <li>Store predictions as PNG</li>
                <li>User can change station as needed</li>
            </ol>
            <li> <em> Requirements </em> Display train predictions on LED board </li> 
            <ol type = 'i'>
                <li> Make sure text fits on board</li>
                <li>Refresh text every 10 seconds</li>
            </ol>
        </ol>
        <p>
            Pulling WMATA train predictions for a given station every 10 seconds was simple enough through their WMATA's developer API. The harder part was figuring out how to display and update the predictions on the LED board. Luckily, the rpi-rgb-led-matrix  <a> <href = https://github.com/hzeller/rpi-rgb-led-matrix> rpi-rgb-led-matrix library </a> built by Henner Zeller can be used to control LED panels from a computer like a Raspberry Pi. With the rpi-rgb-led-matrix Python bindings, you can choose to display scrolling text or static images on a single board or string of boards. I preferred the PNG image option so I could display three incoming trains at once; which meant I first needed to convert a string object to a PNG image.  I've played with scraping text off images with OCR packages, but had never thought of converting a text to an image. Luckily, the Python Imaging Library (PIL/Pillow) simplified this process to a few lines of code.
        </p>
        <p>
            A basic process flow is below. The Prod_Prediction_Ticker.py and Prod_Display_Image.py files run concurrently and refresh every 10 seconds.
        </p>
        <p>
            <center>
                <img src="Process_Flow.png" alt="Software process flow" width="700" height="300">
            </center>
        </p>
    </ol>
    <p>
        <h2> <u> What I learned </u> </h2>
    </p>
    <p>
    <ul class = posts type = circle>
        <li>Building something physical is super rewarding</li>
        <ul type = square> 
            Most of my projects end up as a model or dashboard. It was fun to make something with a physical end product that I can keep on my desk
        </ul>
        <li>Cloud services are awesome</li>
        <ul type = square> 
            Imaging and setting up a Raspberry Pi for an SSH connection takes a decent amount of time and know how. This really puts into perspective how nice it is to spin up an EC2 instance and be ready to code in a couple minutes. Working with a new Linux computer first hand gave me an appreciation for what goes on behind the scenes with VMs.
        </ul>
        <li>Linux syntax is important</li>
        <ul type = square> 
            Everything I did on the Raspberry Pi from downloading libraries, scping files, updating python scripts was through the command line. A basic understanding of the useful commands was super important to work quickly. I started this project really only knowing cd and ls but I quickly became more comfortable in the command line. I included useful commands in this projects Github readme that I used throughout this project.
        </ul>
    </ul>
    </p>
    <p>
        If you are interested in building one of these for DC or another city with real-time accessible data, let me know!
    </p>
</div>